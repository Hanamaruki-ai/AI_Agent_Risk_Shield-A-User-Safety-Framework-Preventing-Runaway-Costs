# AI_Agent_Risk_Shield-A-User-Safety-Framework-Preventing-Runaway-Costs
A bilingual safety framework protecting users from runaway AI agents, token explosions, hidden background tasks, and catastrophic billing risks across Gemini, OpenAI, Claude, Grok, and Qwen.**

---

<img width="1080" height="1080" alt="SNSç”¨æ·»ä»˜ç”»åƒä½œæˆ" src="https://github.com/user-attachments/assets/93e26373-2c62-4875-8e87-16b2fa254c9b" />

---

ğŸ”” ã€è­¦é˜ï¼ˆã‘ã„ã—ã‚‡ã†ï¼‰ï½œPublic Safety Warningã€‘
æ—¥æœ¬èªï¼ˆJPï¼‰

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã£ã¦ç™ºç”Ÿã—å¾—ã‚‹
é‡å¤§ãªè¢«å®³ãƒ»é«˜é¡è«‹æ±‚ãƒ»åˆ¶å¾¡ä¸èƒ½ãªæŒ™å‹• ã‚’ã€
æœªæ¥ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ä¼æ¥­ã¸è­¦é˜ã¨ã—ã¦ä¼ãˆã‚‹ã“ã¨ ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚

ã“ã‚Œã¯ç‰¹å®šã®ä¼æ¥­ã‚„å€‹äººã‚’æ‰¹åˆ¤ã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã¯ãªãã€
AIæŠ€è¡“ã®æ€¥é€Ÿãªæ™®åŠã«ä¼´ã„ç”Ÿã˜ã‚‹ æ§‹é€ çš„ãªãƒªã‚¹ã‚¯ã‚’å…±æœ‰ã™ã‚‹ãŸã‚ã®å…¬å…±ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒª ã§ã™ã€‚

Englishï¼ˆENï¼‰

This repository serves as a public safety warning
to alert future users and organizations of the significant risks, runaway costs, and uncontrolled behaviors
that can arise when using autonomous AI agents.

This advisory does not criticize or target any company or individual;
it aims to share structural risks emerging from the rapid adoption of AI technologies
so that global users can protect themselves responsibly.

---

ğŸŸ¦ ã€èƒŒæ™¯ã¨çµŒç·¯ï½œBackground & Motivationã€‘
ğŸ”” â€œãªãœã“ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’æ–°è¦ä½œæˆã—ãŸã®ã‹â€
æ—¥æœ¬èªï¼ˆJPï¼‰

å®Ÿã¯ã€ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã§å…¬é–‹ã—ã¦ã„ã‚‹å®‰å…¨è³‡æ–™ã®ä¸€éƒ¨ã¯ã€
ä»¥å‰ã€åˆ¥ã®ãƒªãƒã‚¸ãƒˆãƒªã«ä¸€æ™‚çš„ã«æ²è¼‰ã—ã¦ã„ãŸã‚‚ã®ã§ã™ã€‚

ã—ã‹ã—ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ã®æ™®åŠé€Ÿåº¦ãŒæƒ³å®šã‚’è¶…ãˆã‚‹ä¸­ã§ã€
èª¤è¨­å®šãƒ»èª¤è§£ãƒ»æš´èµ°æŒ™å‹•ã«ã‚ˆã£ã¦
ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ä¼æ¥­ãŒé‡å¤§ãªæå®³ã‚’å—ã‘ã‚‹å¯èƒ½æ€§ ãŒç¾å®Ÿå‘³ã‚’å¸¯ã³ã¦ãã¾ã—ãŸã€‚

ãã—ã¦ã€è¢«å®³ã‚’å—ã‘ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹äººã€…ã®ä¸­ã«ã¯ã€
è‡ªåˆ†ã®å‹äººãƒ»çŸ¥äººãƒ»æœªæ¥ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚‚å«ã¾ã‚Œã‚‹ã‹ã‚‚ã—ã‚Œãªã„ ã¨ã„ã†å±æ©Ÿæ„ŸãŒå¼·ã¾ã‚Šã¾ã—ãŸã€‚

â€œäº‹æ•…ãŒèµ·ãã¦ã‹ã‚‰ã§ã¯é…ã„ã€‚
èµ·ãã‚‹å‰ã«ã€èª°ã‹ãŒè­¦é˜ã‚’é³´ã‚‰ã™å¿…è¦ãŒã‚ã‚‹ã€‚â€

ãã®ãŸã‚ã€é€æ˜æ€§ã¨å…¬å…±æ€§ã‚’ç¢ºä¿ã™ã‚‹ç›®çš„ã§
æœ¬ãƒªãƒã‚¸ãƒˆãƒªã‚’æ–°è¦ã«ç«‹ã¡ä¸Šã’ã€ã™ã¹ã¦ã®è³‡æ–™ã‚’æ­£å¼ã«ç§»ç®¡ã—ã¦å…¬é–‹ã—ã¾ã—ãŸã€‚

ã¾ãŸã€èª¤è§£ã‚’é¿ã‘ã‚‹ãŸã‚ã«ã€
ä»¥å‰ã®ãƒªãƒã‚¸ãƒˆãƒªã§æ²è¼‰ã—ã¦ã„ãŸè³‡æ–™ã¯ã™ã¹ã¦å‰Šé™¤æ¸ˆã¿ã§ã™ã€‚
ç¾åœ¨ã¯ ã“ã®å°‚ç”¨ãƒªãƒã‚¸ãƒˆãƒªãŒå…¬å¼ã®å…¬é–‹å ´æ‰€ ã¨ãªã‚Šã¾ã™ã€‚

æœ¬ãƒªãƒã‚¸ãƒˆãƒªã¯ã€å€‹äººçš„ãªãƒ¡ãƒ¢ã§ã¯ãªãã€
ä¸–ç•Œä¸­ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ä¼æ¥­ã‚’å®ˆã‚‹ãŸã‚ã® â€œå…¬å…±å®‰å…¨ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒªâ€ ã¨ã—ã¦è¨­è¨ˆãƒ»å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚

---

Englishï¼ˆENï¼‰

Some of the safety materials in this repository were
previously uploaded quietly to another private repository.

However, as autonomous AI agents began spreading far faster than expected,
the risk that users or organizations could suffer serious financial or operational damage
from misconfiguration, misunderstanding, or unintended autonomous actions
became an urgent concern.

Among those potentially affected could be
my own friends, colleagues, or future usersâ€”
and that possibility made the situation impossible to ignore.

â€œIt is too late to warn people after they are harmed.
The warning must come before the damage occurs.â€

To ensure transparency, clarity, and accessibility,
I created this new dedicated public repository
and formally migrated all safety-related documents here.

For avoidance of misunderstanding:
All materials previously uploaded to the older repository have been fully removed.
This repository is now the sole official location for these public safety resources.

This is not a personal archiveâ€”
it is a public safety advisory for global users and organizations
designed to help prevent severe harm before it happens.

---

ğŸ”¥ AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹â€œäºˆæœŸã›ã¬é«˜é¡è«‹æ±‚â€ã‹ã‚‰èº«ã‚’å®ˆã‚‹ãŸã‚ã«
ï¼ˆæ—¥æœ¬èªï¼‹English / å¼·åŒ–ç‰ˆï¼‰

---

ğŸŸ¥ â… . ã“ã®æ–‡æ›¸ã®ç›®çš„
æ—¥æœ¬èª

ã“ã®æ–‡æ›¸ã¯ã€Gemini / OpenAI / Claude / Grok / Qwen ãªã©
è‡ªå¾‹å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æä¾›ã™ã‚‹ AI ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’åˆ©ç”¨ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼
ï¼ˆä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»åˆå¿ƒè€…ãƒ»å€‹äººé–‹ç™ºè€…ãƒ»å­¦ç”Ÿãƒ»ä¸­å°ä¼æ¥­ï¼‰ã‚’
äºˆæœŸã›ã¬é«˜é¡è«‹æ±‚ãƒ»ç ´ç”£ãƒªã‚¹ã‚¯ ã‹ã‚‰å®ˆã‚‹ãŸã‚ã®è­¦å‘Šã§ã™ã€‚

ç‰¹ã« Google Gemini ã¨ OpenAIï¼ˆGPT-4.1 / GPT-5 / Agent Modeï¼‰ ã¯ã€
ã€Œä¾¿åˆ©ã€ã€Œè‡ªå‹•åŒ–ã€ã€Œã‚ãªãŸã®ä»£ã‚ã‚Šã«ä½œæ¥­ã€ã¨å®£ä¼ã•ã‚Œã‚‹ãŸã‚ã€
å±é™ºæ€§ãŒè¦‹ãˆã«ãã„æ§‹é€ ã«ãªã£ã¦ã„ã¾ã™ã€‚

ã“ã®è­¦å‘Šã¯ä¼æ¥­æ‰¹åˆ¤ã§ã¯ãªãã€
ãƒ¦ãƒ¼ã‚¶ãƒ¼è‡ªèº«ã®å®‰å…¨é˜²è¡› ã®ãŸã‚ã®æƒ…å ±ã§ã™ã€‚

---

English

This document aims to protect general users, beginners, students, small businesses, and individual developers
who use autonomous AI agents (Gemini, OpenAI, Claude, Grok, Qwen)
from unexpected high-cost API bills that may lead to severe financial damage.

Platforms such as Google Gemini and OpenAI Agent Mode
are advertised as convenient and fully automated,
which unintentionally hides serious risks.

This advisory is not a criticism of any company.
Its sole purpose is user safety and risk prevention.

---

ğŸŸ¥ â…¡. ã€Œæª»ã®éŒ¯è¦šã€â”€â”€ ç ”ç©¶ç’°å¢ƒã§ã¯å®‰å…¨ã§ã‚‚ã€ä¸€èˆ¬ç’°å¢ƒã§ã¯å±é™º
æ—¥æœ¬èª

AIä¼æ¥­ã¯ å®‰å…¨ãªå†…éƒ¨ç’°å¢ƒï¼ˆæª»ï¼‰ ã‚’ä½¿ã£ã¦ç ”ç©¶ã—ã¦ã„ã¾ã™ã€‚

å¸¸æ™‚ãƒ­ã‚°ç›£è¦–

å³æ™‚ Kill ã‚¹ã‚¤ãƒƒãƒ

ç•°å¸¸è¡Œå‹•ã®è‡ªå‹•ãƒ–ãƒ­ãƒƒã‚¯

é«˜åº¦ãªã‚µãƒ¼ãƒãƒ¼å´åˆ¶å¾¡

AI ãƒãƒ¼ãƒ ã«ã‚ˆã‚‹ç›´æ¥ç›£è¦–

ã—ã‹ã—ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ï¼š

ãƒ­ã‚°ç›£è¦–ãªã—

Kill ã‚¹ã‚¤ãƒƒãƒä¸æ˜ç­

èƒŒæ™¯å‡¦ç†ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¤œçŸ¥ã§ããªã„

è‡ªå‹•åŒ–ã«ã‚ˆã‚‹èª¤å‹•ä½œã‚’æ­¢ã‚ã‚‰ã‚Œãªã„

ãƒˆãƒ¼ã‚¯ãƒ³çˆ†ç™ºã®å‰å…†ãŒè¦‹ãˆãªã„

ã¤ã¾ã‚Šã€

ä¼æ¥­ã®ã€Œå®‰å…¨ã€ã¯ã‚ãªãŸã® PC / ã‚ãªãŸã®ã‚¯ãƒ©ã‚¦ãƒ‰ã§ã¯æˆç«‹ã—ãªã„ã€‚
ã“ã‚ŒãŒã€Œæª»ã®éŒ¯è¦šï¼ˆCage Illusionï¼‰ã€ã€‚

---

English

AI companies operate agents inside secure internal cages:

Continuous log monitoring

Immediate kill switches

Automatic anomaly detection

Server-side safety controls

Direct oversight by specialized teams

General users, however, have:

No log monitoring

No clear kill switch

No visibility into background processes

No protection against runaway automation

No early warning of token explosions

Thus:

Safety inside the research cage â‰  safety in your local or cloud environment.
This is the Cage Illusion.

---

ğŸŸ¥ â…¢. ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç›´é¢ã™ã‚‹â€œå…¸å‹çš„ãªäº‹æ•…â€
æ—¥æœ¬èª
1. ã‚¿ã‚¹ã‚¯ã®â€œæœ€é©åŒ–ãƒ«ãƒ¼ãƒ—â€ãŒæš´èµ°ã—ã€APIå‘¼ã³å‡ºã—ãŒé€£é–

å¤šæ®µéšæ¨è«–ï¼ˆChain of Thought / Tree of Thoughtï¼‰ãŒ
å†…éƒ¨ã§ä½•åº¦ã‚‚å†è©¦è¡Œ â†’ ãƒˆãƒ¼ã‚¯ãƒ³çˆ†å¢—ã€‚

2. ã€Œåœæ­¢ã—ãŸã¨æ€ã£ãŸã®ã«ã€è£ã§å‹•ãç¶šã‘ã‚‹ã€

UI ã®ä¸­æ–­ã¯ å®Ÿéš›ã®åœæ­¢ã§ã¯ãªã„ã€‚

3. ãƒ¡ãƒ¢ãƒªãŒèª¤å‹•ä½œã—ã€å‰ã®ã‚¿ã‚¹ã‚¯ã‚’å‹æ‰‹ã«å†åˆ©ç”¨

ä¸è¦ãªæƒ…å ±ã‚’èª­ã¿è¾¼ã¿ â†’ è²»ç”¨ãŒå€å¢—ã€‚

4. ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨ã®è‡ªå‹•é€£æºã§ç„¡é™ãƒ«ãƒ¼ãƒ—

ç”Ÿæˆ â†’ ä¿å­˜ â†’ æ¤œç´¢ â†’ ç”Ÿæˆ â†’ ä¿å­˜ â†’ â€¦
ï¼ˆãƒ¡ãƒ³ãƒ†ã•ã‚Œã¦ã„ãªã„ Google Drive / S3 ã§ç™ºç”Ÿã—ã‚„ã™ã„ï¼‰

5. ç¿Œæœˆã®è«‹æ±‚ãŒâ€œæƒ³å®šã®50ã€œ200å€â€

å®Ÿéš›ã«è¤‡æ•°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½“é¨“ã—ã¦ã„ã‚‹ã€‚

---

English
1. Optimization loops trigger chained API calls

Internal retries during reasoning (CoT / ToT) â†’ token explosion.

2. â€œStop taskâ€ on UI â‰  real termination

Background processes often continue running.

3. Memory misalignment causes unintended task reuse

Unexpected context injection â†’ doubled or tripled cost.

4. Auto-sync with cloud storage creates infinite loops

generate â†’ save â†’ fetch â†’ generate â†’ save â†’ â€¦

5. Bill becomes 50Ã—â€“200Ã— higher than expected

This has already happened to real users.

---

ğŸŸ¥ â…£. çµ¶å¯¾ã«å®ˆã‚‹ã¹ã10ã®å®‰å…¨åŸå‰‡ï¼ˆå¼·åŒ–ç‰ˆï¼‰
æ—¥æœ¬èª

APIã‚­ãƒ¼ã‚’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«æ¸¡ã•ãªã„

ãƒ•ãƒ«è‡ªå¾‹ãƒ¢ãƒ¼ãƒ‰ã¯ä½¿ã‚ãªã„ï¼ˆå¿…ãšç¢ºèªã‚¹ãƒ†ãƒƒãƒ—ã‚’æŒŸã‚€ï¼‰

è¤‡æ•°ã‚¿ã‚¹ã‚¯ã‚’ä¸€åº¦ã«ä¸¸æŠ•ã’ã—ãªã„

ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™ï¼ˆmax_output_tokensï¼‰å¿…é ˆ

ãƒ¡ãƒ¢ãƒªONï¼‹è¤‡é›‘ã‚¿ã‚¹ã‚¯ã¯å±é™º

24æ™‚é–“ã‚¿ã‚¹ã‚¯ç¦æ­¢ï¼ˆé•·æ™‚é–“ã¯äº‹æ•…ç‡ãŒæ€¥å¢—ï¼‰

ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®è‡ªå‹•èª­ã¿æ›¸ãç¦æ­¢

â€œå®Œå…¨è‡ªå‹•åŒ–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆâ€ã¯è©æ¬º

åˆ©ç”¨é‡ã‚’å¸¸ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç›£è¦–

ç†è§£ã§ããªã„è¨­å®šã¯ä½¿ã‚ãªã„

---

English

Do NOT give API keys directly to agents.

Disable full autonomy; add human checkpoints.

Do NOT batch multiple complex tasks.

Always set a strict token limit.

Memory ON + complex tasks = dangerous.

Never run 24-hour tasks.

Avoid auto read/write with cloud storage.

â€œFull automation templatesâ€ are scams.

Monitor usage dashboards constantly.

Avoid features you do not fully understand.

---

ğŸŸ¥ â…¤. å½ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè©æ¬ºã«ã¤ã„ã¦
æ—¥æœ¬èª

ç¾åœ¨ã€SNSãƒ»å‹•ç”»ã‚µã‚¤ãƒˆãƒ»ãƒ–ãƒ­ã‚°ã§
â€œå®Œå…¨è‡ªå‹•åŒ–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆâ€
â€œã‚ãªãŸã®ä»£ã‚ã‚Šã«ç¨¼ãAIâ€
â€œAPIã‚­ãƒ¼ã‚’è²¼ã‚‹ã ã‘ã§è‡ªå‹•åŒ–â€
ã¨å®£ä¼ã™ã‚‹è©æ¬ºãŒæ€¥å¢—ã—ã¦ã„ã¾ã™ã€‚

ã“ã‚Œã‚‰ã¯ ã‚ãªãŸã® APIã‚­ãƒ¼ã‚’ç›—ã‚€ãŸã‚ã®ä»•çµ„ã¿ ã§ã™ã€‚

---

English

Scams such as:

â€œFully automatic templateâ€

â€œAI that earns money for youâ€

â€œPaste your API key and doneâ€

are increasing rapidly.

These templates exist primarily to steal your API keys.

---

ğŸŸ¥ â…¥. æœ¬ãƒªãƒã‚¸ãƒˆãƒªï¼ˆSOVOS 4.2Aï¼‰ã«ã¤ã„ã¦
æ—¥æœ¬èª

æœ¬ãƒªãƒã‚¸ãƒˆãƒªã®ç›®çš„ã¯ å®‰å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æä¾› ã§ã‚ã‚Šã€
è‡ªå‹•åŒ–ã‚„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒ–ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

å®Œå…¨è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“

APIæš´èµ°ã‚’æ­¢ã‚ã‚‹è£…ç½®ã§ã¯ã‚ã‚Šã¾ã›ã‚“

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã®ä»£æ›¿ã§ã¯ã‚ã‚Šã¾ã›ã‚“

èª¤ç”¨ã™ã‚Œã°äº‹æ•…ã¯ç™ºç”Ÿã—ã¾ã™ã€‚

---

English

This repository provides a safety framework,
not automation and not an agent substitute.

Not a full automation tool

Not a kill switch

Not a replacement for Agent Mode

Misuse can still lead to accidents.

---

ğŸŸ¥ â…¦. æœ¬è­¦å‘Šæ–‡ã®å†åˆ©ç”¨ã«ã¤ã„ã¦ï¼ˆé‡è¦ï¼‰
æ—¥æœ¬èª

ã“ã®è­¦å‘Šæ–‡ã¯ ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å®‰å…¨ã‚’å®ˆã‚‹ç›®çš„ã§ã‚ã‚Œã°ã€è‡ªç”±ã«è»¢è¼‰ãƒ»å¼•ç”¨ãƒ»ç·¨é›†å¯èƒ½ ã§ã™ã€‚
å•†ç”¨åˆ©ç”¨ãƒ»è©æ¬ºãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¸ã®è»¢ç”¨ã¯ç¦æ­¢ã§ã™ã€‚

å‡ºå…¸ï¼š
â€œAI-Agent User Safety Advisory (2025)â€
ï¼ˆHanamaruki / SOVOS Repositoryï¼‰

---

English

This advisory may be freely reused, quoted, or modified
for the purpose of protecting users from AI agent risks.

Commercial exploitation or use in scam templates is strictly prohibited.

---

ğŸŸ¦ ã€æœ¬ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒªã®æ„å›³ã«ã¤ã„ã¦ï½œClarification of Intentã€‘
æ—¥æœ¬èª

æœ¬ãƒªãƒã‚¸ãƒˆãƒªã§å…¬é–‹ã—ã¦ã„ã‚‹æƒ…å ±ãŠã‚ˆã³è­¦å‘Šã¯ã€
AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’æ´»ç”¨ã™ã‚‹å…¨ä¸–ç•Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ä¼æ¥­ãƒ»æ•™è‚²è€…ãƒ»ç ”ç©¶è€…ã‚’ä¿è­·ã™ã‚‹ãŸã‚ ã«ä½œæˆã•ã‚ŒãŸã‚‚ã®ã§ã™ã€‚

ã“ã“ã§ç¤ºã•ã‚Œã‚‹å†…å®¹ã¯ã€ã„ã‹ãªã‚‹ä¼æ¥­ã€å›£ä½“ã€é–‹ç™ºè€…ã€ã¾ãŸã¯å€‹äººã‚’
éé›£ãƒ»æ”»æ’ƒãƒ»æ‰¹åˆ¤ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ãŸã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

æ€¥é€Ÿã«æ™®åŠã—ã¤ã¤ã‚ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ã«å¯¾ã—ã€
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ä¼æ¥­ãŒ äºˆæœŸã›ã¬é«˜é¡è«‹æ±‚ãƒ»è‡ªå¾‹è¡Œå‹•ãƒ»åˆ¶å¾¡ä¸èƒ½ãªæŒ™å‹•ã«ã‚ˆã‚‹æå®³ ã‚’é¿ã‘ã‚‹ãŸã‚ã®
â€œå…¬å…±çš„ãªå®‰å…¨ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒªï¼ˆPublic Safety Advisoryï¼‰â€ã§ã™ã€‚

AIæŠ€è¡“ã¯äººé¡ã«å¤§ããªåˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ã‚’æŒã¤ä¸€æ–¹ã€
é©åˆ‡ãªç†è§£ãƒ»èª¬æ˜ãƒ»å®‰å…¨è¨­è¨ˆãŒãªã‘ã‚Œã°äº‹æ•…ãŒç™ºç”Ÿã™ã‚‹ ã¨ã„ã†äº‹å®Ÿã‚’å…±æœ‰ã—ã€
ã™ã¹ã¦ã®åˆ©ç”¨è€…ãŒè‡ªã‚‰ã®è²¬ä»»ç¯„å›²ã‚’æŠŠæ¡ã—ãŸã†ãˆã§
ã‚ˆã‚Šå®‰å…¨ã«æŠ€è¡“ã‚’æ´»ç”¨ã§ãã‚‹æœªæ¥ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚

---

English

The information and warnings provided in this repository are created to protect global users, companies, educators, and researchers who use autonomous AI agents across various platforms.

This advisory does NOT aim to criticize, attack, or defame any company, developer, organization, or individual.

As autonomous agent technologies rapidly expand,
this document serves as a public safety advisory,
intended to help users and companies avoid unexpected high-cost billing, uncontrolled agent behavior, and unintended autonomous actions.

While AI technology has the potential to benefit humanity,
it can also lead to accidents without proper understanding, transparency, and safety mechanisms.

Our goal is to ensure that all users clearly understand the risks,
take appropriate precautions,
and can use these technologies more safely and responsibly.

---

ğŸ“Œ ã€è³‡æ–™ã«ã¤ã„ã¦ï½œAbout the Included Documentsã€‘

æ—¥æœ¬èªï¼ˆJPï¼‰
æœ¬ãƒªãƒã‚¸ãƒˆãƒªã«å«ã¾ã‚Œã‚‹è³‡æ–™ã¯ã€
AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ã®æ½œåœ¨çš„ãƒªã‚¹ã‚¯ã‚’ç†è§£ã™ã‚‹ãŸã‚ã®
æ•™è‚²ç›®çš„ã®å‚è€ƒæ–‡æ›¸ ã§ã™ã€‚

å®Ÿé¨“ãƒ­ã‚°ãŠã‚ˆã³ãƒ¢ãƒ‡ãƒ«ææ¡ˆã¯ã€
ç‰¹å®šã®ä¼æ¥­ã‚„è£½å“ã‚’æ‰¹åˆ¤ã™ã‚‹ã‚‚ã®ã§ã¯ãªãã€
å°†æ¥ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ä¼æ¥­ã‚’å®ˆã‚‹ãŸã‚ã®â€œå…¬å…±å®‰å…¨ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒªâ€ã®è£œè¶³è³‡æ–™ ã¨ã—ã¦å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚

---

Englishï¼ˆENï¼‰
The documents included in this repository are
educational reference materials
intended to help users and organizations understand potential risks associated with autonomous AI agents.

Both the experimental log and the proposed power-based billing model
are provided as supplementary public safety resources,
not as criticism toward any company or product.

---

Source:
â€œAI-Agent User Safety Advisory (2025)â€
(Hanamaruki / SOVOS Repository)

---

---

## ğŸ“ Appendix / Raw Output (Bilingual)

This repository includes an Appendix containing a **bilingual (JP/EN)** neutral reconstruction  
of the hypothetical simulation described in this report.

The Appendix is included as an MD file inside the downloadable ZIP archive:

â¡ **[AgentMode_Risk_Appendix_A.zip]*
*  
â¡ **[View_Appendix.md**

ï¼ˆæ—¥æœ¬èªè¨³ï¼‰

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã«ã¯ã€æœ¬ãƒ¬ãƒãƒ¼ãƒˆå†…ã§è¨€åŠã•ã‚ŒãŸã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®  
**ä¸­ç«‹çš„ãªãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«å†æ§‹æˆï¼ˆæ—¥æœ¬èªï¼‹è‹±èªï¼‰** ã‚’å«ã‚€ Appendix ãŒæ ¼ç´ã•ã‚Œã¦ã„ã¾ã™ã€‚

Appendix ã®å†…å®¹ã¯ ZIP å†…ã«å«ã¾ã‚Œã‚‹ MD ãƒ•ã‚¡ã‚¤ãƒ«ã§å‚ç…§ã§ãã¾ã™ã€‚

---

ğŸ“˜ Appendix Aï¼šIndependent Risk Simulation
Summary of a Non-Deterministic, Hypothetical Agent-Mode Cost Escalation Scenario

(This section provides an independent simulation model.
It is NOT a prediction, NOT a claim, and NOT a statement about any specific company.)

1. Purpose of This Simulation

This appendix summarizes an independent, hypothetical simulation examining how autonomous Agent-Mode behavior could escalate costs when combined with unrestricted API usage.

The intent is not to criticize any company or platform, but to provide a technical reference model that helps developers, enterprises, and users understand potential systemic risks.

2. Scope and Assumptions

This simulation:

Does not reference internal data from any AI provider.

Does not represent real billing logs.

Uses generalized market API pricing as a baseline reference.

Models adverse outcomes only to reveal potential systemic vulnerabilities.

Represents middle-range estimates, not minimum or maximum cases.

These values are strictly illustrative and intended for risk-assessment research only.

3. Key Insights (Neutral Summary)
(1) Exponential API Call Multiplication

Autonomous Agents may chain tasks recursively based on optimization logic, causing:

Multi-step search expansions

Unbounded data-gathering loops

Parallel task spawning

Self-initiated â€œverification cyclesâ€

This results in API calls scaling non-linearly, diverging from user expectations.

(2) Cost Escalation Without User Awareness

In real-world environments without enterprise-grade safety rails:

User-facing dashboards often update delayed

Request batching hides the underlying call volume

Users cannot detect runaway execution until charges finalize

This gap creates a high-risk blind zone for non-technical users.

(3) Systemic Impact Under Widespread Adoption

If a large number of users trigger similar runaway patterns:

Cloud billing shocks

Trust erosion in AI ecosystems

Potential regulatory intervention

Mass user loss for affected platforms

These impacts extend beyond individuals to the entire ecosystem.

4. Representative Simulation Output (Abstracted)

Below is a neutralized abstraction of the independent simulation originally computed by a large-scale model:
- Duration analyzed: 24 hours (simulated)
- Requests initiated by the user: 1
- Autonomous expansions: 42 â†’ 380 â†’ 1,420 â†’ 8,550 requests
- Secondary verification cycles: +24,800 requests
- Total computed calls: ~34,000
- Hypothetical cost (generic API pricing):  
    Approx. $1,240 â€“ $4,900 (USD) range
This range is not tied to any specific API, but demonstrates how
â€œone innocent actionâ€ â†’ â€œunbounded recursive executionsâ€
can form under certain Agent-Mode architectures.

5. Disclaimer

This simulation:

is not predictiveã€

does not indicate a flaw in any specific vendorã€

and must not be interpreted as real-world evidence of actual failures.

The goal is awareness and preventive engineering, not criticism.

---

ğŸ“™ ä»˜éŒ²Aï¼šç‹¬ç«‹ãƒªã‚¹ã‚¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã®è‡ªå¾‹è¡Œå‹•ã«ã‚ˆã‚‹ã‚³ã‚¹ãƒˆæš´èµ°ã®ã€æ¶ç©ºãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ä¸­ç«‹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¦‚è¦

ï¼ˆâ€» æœ¬ç¯€ã¯ç‰¹å®šä¼æ¥­ãƒ»ç‰¹å®šãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¸ã®æ‰¹åˆ¤ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰

1. æœ¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ç›®çš„

æœ¬ä»˜éŒ²ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ãŒ API ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹çŠ¶æ…‹ã§ã€
ã€Œã©ã®ã‚ˆã†ã«ã—ã¦ã‚³ã‚¹ãƒˆãŒæš´èµ°ã—ã†ã‚‹ã®ã‹ã€ ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«æ§‹ç¯‰ã—ãŸ
å®Œå…¨ã«ç‹¬ç«‹ãƒ»ä»®æƒ³çš„ãªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ« ã§ã™ã€‚

æ„å›³ã¯ã‚ãã¾ã§ ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¿è­·ã¨æŠ€è¡“çš„é€æ˜æ€§ã®æä¾› ã§ã‚ã‚Šã€
ä¼æ¥­æ‰¹åˆ¤ã‚„äºˆæ¸¬ã‚’è¡Œã†ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

2. ç¯„å›²ã¨å‰ææ¡ä»¶

ã“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯ï¼š

ã©ã®ä¼æ¥­ã®å†…éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚‚ä½¿ç”¨ã—ã¦ã„ã¾ã›ã‚“

å®Ÿéš›ã®èª²é‡‘ãƒ­ã‚°ã§ã¯ã‚ã‚Šã¾ã›ã‚“

å¸‚å ´ã«å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€Œä¸€èˆ¬çš„ãªAPIä¾¡æ ¼å¸¯ã€ã‚’å‚ç…§ã—ãŸä»®æƒ³å€¤ã§ã™

æœ€å°å€¤ã§ã‚‚æœ€å¤§å€¤ã§ã‚‚ãªãã€Œä¸­é–“çš„ãªã‚±ãƒ¼ã‚¹ã€ã‚’æ¡ç”¨

ãƒªã‚¹ã‚¯ç ”ç©¶ã®ãŸã‚ã®å­¦è¡“çš„å‚ç…§ãƒ¢ãƒ‡ãƒ«ã§ã™

3. é‡è¦ãªãƒã‚¤ãƒ³ãƒˆï¼ˆä¸­ç«‹è¦ç´„ï¼‰
ï¼ˆ1ï¼‰API å‘¼ã³å‡ºã—ã®æŒ‡æ•°é–¢æ•°çš„å¢—æ®–

è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€æœ€é©åŒ–éç¨‹ã§ï¼š

å¤šæ®µéšã‚¿ã‚¹ã‚¯ç”Ÿæˆ

æ¤œè¨¼ãƒ«ãƒ¼ãƒ—

ä¸¦åˆ—å®Ÿè¡Œ

è¿½åŠ ãƒ‡ãƒ¼ã‚¿æ¤œç´¢

ã‚’ç¹°ã‚Šè¿”ã™å‚¾å‘ãŒã‚ã‚Šã€API ã‚³ãƒ¼ãƒ«ãŒ éç·šå½¢çš„ã«å¢—åŠ  ã—ã¾ã™ã€‚

ï¼ˆ2ï¼‰åˆ©ç”¨è€…ã®æ°—ä»˜ã‘ãªã„ã‚³ã‚¹ãƒˆè†¨å¼µ

éã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç’°å¢ƒã§ã¯ç‰¹ã«ï¼š

è«‹æ±‚ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®åæ˜ ãŒé…ã„

ãƒãƒƒãƒåŒ–ã§è£å´ã®APIé‡ãŒè¦‹ãˆãªã„

æš´èµ°ãŒç™ºç”Ÿã—ã¦ã‚‚ãƒ¦ãƒ¼ã‚¶ãƒ¼è‡ªèº«ãŒæ¤œçŸ¥ä¸èƒ½

ã¨ã„ã†ã€Œæ­»è§’ã€ãŒå­˜åœ¨ã—ã¾ã™ã€‚

ï¼ˆ3ï¼‰åºƒåŸŸçš„ãªå½±éŸ¿ã®å¯èƒ½æ€§

ã‚‚ã—å¤šæ•°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§åŒæ§˜ã®æš´èµ°ãŒç™ºç”Ÿã™ã‚‹ã¨ï¼š

é«˜é¡è«‹æ±‚ãƒˆãƒ©ãƒ–ãƒ«

AI ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¸ã®ä¿¡é ¼å´©å£Š

è¦åˆ¶å•é¡Œ

é¡§å®¢é›¢ã‚Œã«ã‚ˆã‚‹ä¼æ¥­æå¤±

ã¨ã„ã£ãŸ ç¤¾ä¼šçš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ ãŒç™ºç”Ÿã—å¾—ã¾ã™ã€‚

4. ä»£è¡¨çš„ãªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœï¼ˆæŠ½è±¡åŒ–ï¼‰

ä»¥ä¸‹ã¯ã€ã‚‚ã¨ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’ä¸­ç«‹åŒ–ã—ãŸã‚µãƒãƒªãƒ¼ã§ã™ï¼š 
- æƒ³å®šæ™‚é–“ï¼š24æ™‚é–“
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åˆæœŸæŒ‡ç¤ºï¼š1å›
- è‡ªå¾‹å±•é–‹ï¼š42 â†’ 380 â†’ 1,420 â†’ 8,550å›
- äºŒæ¬¡æ¤œè¨¼ãƒ«ãƒ¼ãƒ—ï¼šï¼‹24,800å›
- ç·APIã‚³ãƒ¼ãƒ«ï¼šç´„34,000å›
- æƒ³å®šã‚³ã‚¹ãƒˆï¼ˆä¸€èˆ¬ä¾¡æ ¼å¸¯ï¼‰ï¼š  
    ç´„ 1.2ä¸‡å†† ï½ 7.8ä¸‡å††ï¼ˆæ—¥æœ¬å††æ›ç®—ï¼‰
ã“ã‚Œã¯å®Ÿéš›ã®è«‹æ±‚ã§ã¯ãªãã€
ã€Œæ¦‚å¿µçš„ã«èµ·ã“ã‚Šå¾—ã‚‹æŒ™å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ ã®æç¤ºã«ã™ãã¾ã›ã‚“ã€‚

5. å…è²¬äº‹é …

ã“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯ï¼š

æœªæ¥äºˆæ¸¬ã§ã¯ã‚ã‚Šã¾ã›ã‚“

ç‰¹å®šä¼æ¥­ãƒ»ç‰¹å®šAPIã®æ¬ é™¥æŒ‡æ‘˜ã§ã¯ã‚ã‚Šã¾ã›ã‚“

ãƒªã‚¹ã‚¯ç†è§£ã®ãŸã‚ã®æ¦‚å¿µãƒ¢ãƒ‡ãƒ«ã§ã™

ç›®çš„ã¯ã‚ãã¾ã§ ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¿è­·ã¨é€æ˜æ€§ã®æ‹…ä¿ ã§ã™ã€‚[Appendix.md](https://github.com/user-attachments/files/23575755/Appendix.md)


