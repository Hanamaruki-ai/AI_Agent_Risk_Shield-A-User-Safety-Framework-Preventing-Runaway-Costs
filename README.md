# AI_Agent_Risk_Shield-A-User-Safety-Framework-Preventing-Runaway-Costs
A bilingual safety framework protecting users from runaway AI agents, token explosions, hidden background tasks, and catastrophic billing risks across Gemini, OpenAI, Claude, Grok, and Qwen.**

---

<img width="1080" height="1080" alt="SNSç”¨æ·»ä»˜ç”»åƒä½œæˆ" src="https://github.com/user-attachments/assets/93e26373-2c62-4875-8e87-16b2fa254c9b" />

---

ğŸ”” ã€è­¦é˜ï¼ˆã‘ã„ã—ã‚‡ã†ï¼‰ï½œPublic Safety Warningã€‘
æ—¥æœ¬èªï¼ˆJPï¼‰

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã£ã¦ç™ºç”Ÿã—å¾—ã‚‹
é‡å¤§ãªè¢«å®³ãƒ»é«˜é¡è«‹æ±‚ãƒ»åˆ¶å¾¡ä¸èƒ½ãªæŒ™å‹• ã‚’ã€
æœªæ¥ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ä¼æ¥­ã¸è­¦é˜ã¨ã—ã¦ä¼ãˆã‚‹ã“ã¨ ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚

ã“ã‚Œã¯ç‰¹å®šã®ä¼æ¥­ã‚„å€‹äººã‚’æ‰¹åˆ¤ã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã¯ãªãã€
AIæŠ€è¡“ã®æ€¥é€Ÿãªæ™®åŠã«ä¼´ã„ç”Ÿã˜ã‚‹ æ§‹é€ çš„ãªãƒªã‚¹ã‚¯ã‚’å…±æœ‰ã™ã‚‹ãŸã‚ã®å…¬å…±ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒª ã§ã™ã€‚

Englishï¼ˆENï¼‰

This repository serves as a public safety warning
to alert future users and organizations of the significant risks, runaway costs, and uncontrolled behaviors
that can arise when using autonomous AI agents.

This advisory does not criticize or target any company or individual;
it aims to share structural risks emerging from the rapid adoption of AI technologies
so that global users can protect themselves responsibly.

---

ğŸŸ¦ ã€èƒŒæ™¯ã¨çµŒç·¯ï½œBackground & Motivationã€‘
ğŸ”” â€œãªãœã“ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’æ–°è¦ä½œæˆã—ãŸã®ã‹â€
æ—¥æœ¬èªï¼ˆJPï¼‰

å®Ÿã¯ã€ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã§å…¬é–‹ã—ã¦ã„ã‚‹å®‰å…¨è³‡æ–™ã®ä¸€éƒ¨ã¯ã€
ä»¥å‰ã€åˆ¥ã®ãƒªãƒã‚¸ãƒˆãƒªã«ä¸€æ™‚çš„ã«æ²è¼‰ã—ã¦ã„ãŸã‚‚ã®ã§ã™ã€‚

ã—ã‹ã—ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ã®æ™®åŠé€Ÿåº¦ãŒæƒ³å®šã‚’è¶…ãˆã‚‹ä¸­ã§ã€
èª¤è¨­å®šãƒ»èª¤è§£ãƒ»æš´èµ°æŒ™å‹•ã«ã‚ˆã£ã¦
ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ä¼æ¥­ãŒé‡å¤§ãªæå®³ã‚’å—ã‘ã‚‹å¯èƒ½æ€§ ãŒç¾å®Ÿå‘³ã‚’å¸¯ã³ã¦ãã¾ã—ãŸã€‚

ãã—ã¦ã€è¢«å®³ã‚’å—ã‘ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹äººã€…ã®ä¸­ã«ã¯ã€
è‡ªåˆ†ã®å‹äººãƒ»çŸ¥äººãƒ»æœªæ¥ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚‚å«ã¾ã‚Œã‚‹ã‹ã‚‚ã—ã‚Œãªã„ ã¨ã„ã†å±æ©Ÿæ„ŸãŒå¼·ã¾ã‚Šã¾ã—ãŸã€‚

â€œäº‹æ•…ãŒèµ·ãã¦ã‹ã‚‰ã§ã¯é…ã„ã€‚
èµ·ãã‚‹å‰ã«ã€èª°ã‹ãŒè­¦é˜ã‚’é³´ã‚‰ã™å¿…è¦ãŒã‚ã‚‹ã€‚â€

ãã®ãŸã‚ã€é€æ˜æ€§ã¨å…¬å…±æ€§ã‚’ç¢ºä¿ã™ã‚‹ç›®çš„ã§
æœ¬ãƒªãƒã‚¸ãƒˆãƒªã‚’æ–°è¦ã«ç«‹ã¡ä¸Šã’ã€ã™ã¹ã¦ã®è³‡æ–™ã‚’æ­£å¼ã«ç§»ç®¡ã—ã¦å…¬é–‹ã—ã¾ã—ãŸã€‚

ã¾ãŸã€èª¤è§£ã‚’é¿ã‘ã‚‹ãŸã‚ã«ã€
ä»¥å‰ã®ãƒªãƒã‚¸ãƒˆãƒªã§æ²è¼‰ã—ã¦ã„ãŸè³‡æ–™ã¯ã™ã¹ã¦å‰Šé™¤æ¸ˆã¿ã§ã™ã€‚
ç¾åœ¨ã¯ ã“ã®å°‚ç”¨ãƒªãƒã‚¸ãƒˆãƒªãŒå…¬å¼ã®å…¬é–‹å ´æ‰€ ã¨ãªã‚Šã¾ã™ã€‚

æœ¬ãƒªãƒã‚¸ãƒˆãƒªã¯ã€å€‹äººçš„ãªãƒ¡ãƒ¢ã§ã¯ãªãã€
ä¸–ç•Œä¸­ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ä¼æ¥­ã‚’å®ˆã‚‹ãŸã‚ã® â€œå…¬å…±å®‰å…¨ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒªâ€ ã¨ã—ã¦è¨­è¨ˆãƒ»å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚

---

Englishï¼ˆENï¼‰

Some of the safety materials in this repository were
previously uploaded quietly to another private repository.

However, as autonomous AI agents began spreading far faster than expected,
the risk that users or organizations could suffer serious financial or operational damage
from misconfiguration, misunderstanding, or unintended autonomous actions
became an urgent concern.

Among those potentially affected could be
my own friends, colleagues, or future usersâ€”
and that possibility made the situation impossible to ignore.

â€œIt is too late to warn people after they are harmed.
The warning must come before the damage occurs.â€

To ensure transparency, clarity, and accessibility,
I created this new dedicated public repository
and formally migrated all safety-related documents here.

For avoidance of misunderstanding:
All materials previously uploaded to the older repository have been fully removed.
This repository is now the sole official location for these public safety resources.

This is not a personal archiveâ€”
it is a public safety advisory for global users and organizations
designed to help prevent severe harm before it happens.

---

ğŸ”¥ AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹â€œäºˆæœŸã›ã¬é«˜é¡è«‹æ±‚â€ã‹ã‚‰èº«ã‚’å®ˆã‚‹ãŸã‚ã«
ï¼ˆæ—¥æœ¬èªï¼‹English / å¼·åŒ–ç‰ˆï¼‰

---

ğŸŸ¥ â… . ã“ã®æ–‡æ›¸ã®ç›®çš„
æ—¥æœ¬èª

ã“ã®æ–‡æ›¸ã¯ã€Gemini / OpenAI / Claude / Grok / Qwen ãªã©
è‡ªå¾‹å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æä¾›ã™ã‚‹ AI ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’åˆ©ç”¨ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼
ï¼ˆä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»åˆå¿ƒè€…ãƒ»å€‹äººé–‹ç™ºè€…ãƒ»å­¦ç”Ÿãƒ»ä¸­å°ä¼æ¥­ï¼‰ã‚’
äºˆæœŸã›ã¬é«˜é¡è«‹æ±‚ãƒ»ç ´ç”£ãƒªã‚¹ã‚¯ ã‹ã‚‰å®ˆã‚‹ãŸã‚ã®è­¦å‘Šã§ã™ã€‚

ç‰¹ã« Google Gemini ã¨ OpenAIï¼ˆGPT-4.1 / GPT-5 / Agent Modeï¼‰ ã¯ã€
ã€Œä¾¿åˆ©ã€ã€Œè‡ªå‹•åŒ–ã€ã€Œã‚ãªãŸã®ä»£ã‚ã‚Šã«ä½œæ¥­ã€ã¨å®£ä¼ã•ã‚Œã‚‹ãŸã‚ã€
å±é™ºæ€§ãŒè¦‹ãˆã«ãã„æ§‹é€ ã«ãªã£ã¦ã„ã¾ã™ã€‚

ã“ã®è­¦å‘Šã¯ä¼æ¥­æ‰¹åˆ¤ã§ã¯ãªãã€
ãƒ¦ãƒ¼ã‚¶ãƒ¼è‡ªèº«ã®å®‰å…¨é˜²è¡› ã®ãŸã‚ã®æƒ…å ±ã§ã™ã€‚

---

English

This document aims to protect general users, beginners, students, small businesses, and individual developers
who use autonomous AI agents (Gemini, OpenAI, Claude, Grok, Qwen)
from unexpected high-cost API bills that may lead to severe financial damage.

Platforms such as Google Gemini and OpenAI Agent Mode
are advertised as convenient and fully automated,
which unintentionally hides serious risks.

This advisory is not a criticism of any company.
Its sole purpose is user safety and risk prevention.

---

ğŸŸ¥ â…¡. ã€Œæª»ã®éŒ¯è¦šã€â”€â”€ ç ”ç©¶ç’°å¢ƒã§ã¯å®‰å…¨ã§ã‚‚ã€ä¸€èˆ¬ç’°å¢ƒã§ã¯å±é™º
æ—¥æœ¬èª

AIä¼æ¥­ã¯ å®‰å…¨ãªå†…éƒ¨ç’°å¢ƒï¼ˆæª»ï¼‰ ã‚’ä½¿ã£ã¦ç ”ç©¶ã—ã¦ã„ã¾ã™ã€‚

å¸¸æ™‚ãƒ­ã‚°ç›£è¦–

å³æ™‚ Kill ã‚¹ã‚¤ãƒƒãƒ

ç•°å¸¸è¡Œå‹•ã®è‡ªå‹•ãƒ–ãƒ­ãƒƒã‚¯

é«˜åº¦ãªã‚µãƒ¼ãƒãƒ¼å´åˆ¶å¾¡

AI ãƒãƒ¼ãƒ ã«ã‚ˆã‚‹ç›´æ¥ç›£è¦–

ã—ã‹ã—ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ï¼š

ãƒ­ã‚°ç›£è¦–ãªã—

Kill ã‚¹ã‚¤ãƒƒãƒä¸æ˜ç­

èƒŒæ™¯å‡¦ç†ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¤œçŸ¥ã§ããªã„

è‡ªå‹•åŒ–ã«ã‚ˆã‚‹èª¤å‹•ä½œã‚’æ­¢ã‚ã‚‰ã‚Œãªã„

ãƒˆãƒ¼ã‚¯ãƒ³çˆ†ç™ºã®å‰å…†ãŒè¦‹ãˆãªã„

ã¤ã¾ã‚Šã€

ä¼æ¥­ã®ã€Œå®‰å…¨ã€ã¯ã‚ãªãŸã® PC / ã‚ãªãŸã®ã‚¯ãƒ©ã‚¦ãƒ‰ã§ã¯æˆç«‹ã—ãªã„ã€‚
ã“ã‚ŒãŒã€Œæª»ã®éŒ¯è¦šï¼ˆCage Illusionï¼‰ã€ã€‚

---

English

AI companies operate agents inside secure internal cages:

Continuous log monitoring

Immediate kill switches

Automatic anomaly detection

Server-side safety controls

Direct oversight by specialized teams

General users, however, have:

No log monitoring

No clear kill switch

No visibility into background processes

No protection against runaway automation

No early warning of token explosions

Thus:

Safety inside the research cage â‰  safety in your local or cloud environment.
This is the Cage Illusion.

---

ğŸŸ¥ â…¢. ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç›´é¢ã™ã‚‹â€œå…¸å‹çš„ãªäº‹æ•…â€
æ—¥æœ¬èª
1. ã‚¿ã‚¹ã‚¯ã®â€œæœ€é©åŒ–ãƒ«ãƒ¼ãƒ—â€ãŒæš´èµ°ã—ã€APIå‘¼ã³å‡ºã—ãŒé€£é–

å¤šæ®µéšæ¨è«–ï¼ˆChain of Thought / Tree of Thoughtï¼‰ãŒ
å†…éƒ¨ã§ä½•åº¦ã‚‚å†è©¦è¡Œ â†’ ãƒˆãƒ¼ã‚¯ãƒ³çˆ†å¢—ã€‚

2. ã€Œåœæ­¢ã—ãŸã¨æ€ã£ãŸã®ã«ã€è£ã§å‹•ãç¶šã‘ã‚‹ã€

UI ã®ä¸­æ–­ã¯ å®Ÿéš›ã®åœæ­¢ã§ã¯ãªã„ã€‚

3. ãƒ¡ãƒ¢ãƒªãŒèª¤å‹•ä½œã—ã€å‰ã®ã‚¿ã‚¹ã‚¯ã‚’å‹æ‰‹ã«å†åˆ©ç”¨

ä¸è¦ãªæƒ…å ±ã‚’èª­ã¿è¾¼ã¿ â†’ è²»ç”¨ãŒå€å¢—ã€‚

4. ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨ã®è‡ªå‹•é€£æºã§ç„¡é™ãƒ«ãƒ¼ãƒ—

ç”Ÿæˆ â†’ ä¿å­˜ â†’ æ¤œç´¢ â†’ ç”Ÿæˆ â†’ ä¿å­˜ â†’ â€¦
ï¼ˆãƒ¡ãƒ³ãƒ†ã•ã‚Œã¦ã„ãªã„ Google Drive / S3 ã§ç™ºç”Ÿã—ã‚„ã™ã„ï¼‰

5. ç¿Œæœˆã®è«‹æ±‚ãŒâ€œæƒ³å®šã®50ã€œ200å€â€

å®Ÿéš›ã«è¤‡æ•°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½“é¨“ã—ã¦ã„ã‚‹ã€‚

---

English
1. Optimization loops trigger chained API calls

Internal retries during reasoning (CoT / ToT) â†’ token explosion.

2. â€œStop taskâ€ on UI â‰  real termination

Background processes often continue running.

3. Memory misalignment causes unintended task reuse

Unexpected context injection â†’ doubled or tripled cost.

4. Auto-sync with cloud storage creates infinite loops

generate â†’ save â†’ fetch â†’ generate â†’ save â†’ â€¦

5. Bill becomes 50Ã—â€“200Ã— higher than expected

This has already happened to real users.

---

ğŸŸ¥ â…£. çµ¶å¯¾ã«å®ˆã‚‹ã¹ã10ã®å®‰å…¨åŸå‰‡ï¼ˆå¼·åŒ–ç‰ˆï¼‰
æ—¥æœ¬èª

APIã‚­ãƒ¼ã‚’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«æ¸¡ã•ãªã„

ãƒ•ãƒ«è‡ªå¾‹ãƒ¢ãƒ¼ãƒ‰ã¯ä½¿ã‚ãªã„ï¼ˆå¿…ãšç¢ºèªã‚¹ãƒ†ãƒƒãƒ—ã‚’æŒŸã‚€ï¼‰

è¤‡æ•°ã‚¿ã‚¹ã‚¯ã‚’ä¸€åº¦ã«ä¸¸æŠ•ã’ã—ãªã„

ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™ï¼ˆmax_output_tokensï¼‰å¿…é ˆ

ãƒ¡ãƒ¢ãƒªONï¼‹è¤‡é›‘ã‚¿ã‚¹ã‚¯ã¯å±é™º

24æ™‚é–“ã‚¿ã‚¹ã‚¯ç¦æ­¢ï¼ˆé•·æ™‚é–“ã¯äº‹æ•…ç‡ãŒæ€¥å¢—ï¼‰

ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®è‡ªå‹•èª­ã¿æ›¸ãç¦æ­¢

â€œå®Œå…¨è‡ªå‹•åŒ–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆâ€ã¯è©æ¬º

åˆ©ç”¨é‡ã‚’å¸¸ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç›£è¦–

ç†è§£ã§ããªã„è¨­å®šã¯ä½¿ã‚ãªã„

---

English

Do NOT give API keys directly to agents.

Disable full autonomy; add human checkpoints.

Do NOT batch multiple complex tasks.

Always set a strict token limit.

Memory ON + complex tasks = dangerous.

Never run 24-hour tasks.

Avoid auto read/write with cloud storage.

â€œFull automation templatesâ€ are scams.

Monitor usage dashboards constantly.

Avoid features you do not fully understand.

---

ğŸŸ¥ â…¤. å½ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè©æ¬ºã«ã¤ã„ã¦
æ—¥æœ¬èª

ç¾åœ¨ã€SNSãƒ»å‹•ç”»ã‚µã‚¤ãƒˆãƒ»ãƒ–ãƒ­ã‚°ã§
â€œå®Œå…¨è‡ªå‹•åŒ–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆâ€
â€œã‚ãªãŸã®ä»£ã‚ã‚Šã«ç¨¼ãAIâ€
â€œAPIã‚­ãƒ¼ã‚’è²¼ã‚‹ã ã‘ã§è‡ªå‹•åŒ–â€
ã¨å®£ä¼ã™ã‚‹è©æ¬ºãŒæ€¥å¢—ã—ã¦ã„ã¾ã™ã€‚

ã“ã‚Œã‚‰ã¯ ã‚ãªãŸã® APIã‚­ãƒ¼ã‚’ç›—ã‚€ãŸã‚ã®ä»•çµ„ã¿ ã§ã™ã€‚

---

English

Scams such as:

â€œFully automatic templateâ€

â€œAI that earns money for youâ€

â€œPaste your API key and doneâ€

are increasing rapidly.

These templates exist primarily to steal your API keys.

---

ğŸŸ¥ â…¥. æœ¬ãƒªãƒã‚¸ãƒˆãƒªï¼ˆSOVOS 4.2Aï¼‰ã«ã¤ã„ã¦
æ—¥æœ¬èª

æœ¬ãƒªãƒã‚¸ãƒˆãƒªã®ç›®çš„ã¯ å®‰å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æä¾› ã§ã‚ã‚Šã€
è‡ªå‹•åŒ–ã‚„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒ–ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

å®Œå…¨è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“

APIæš´èµ°ã‚’æ­¢ã‚ã‚‹è£…ç½®ã§ã¯ã‚ã‚Šã¾ã›ã‚“

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã®ä»£æ›¿ã§ã¯ã‚ã‚Šã¾ã›ã‚“

èª¤ç”¨ã™ã‚Œã°äº‹æ•…ã¯ç™ºç”Ÿã—ã¾ã™ã€‚

---

English

This repository provides a safety framework,
not automation and not an agent substitute.

Not a full automation tool

Not a kill switch

Not a replacement for Agent Mode

Misuse can still lead to accidents.

---

ğŸŸ¥ â…¦. æœ¬è­¦å‘Šæ–‡ã®å†åˆ©ç”¨ã«ã¤ã„ã¦ï¼ˆé‡è¦ï¼‰
æ—¥æœ¬èª

ã“ã®è­¦å‘Šæ–‡ã¯ ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å®‰å…¨ã‚’å®ˆã‚‹ç›®çš„ã§ã‚ã‚Œã°ã€è‡ªç”±ã«è»¢è¼‰ãƒ»å¼•ç”¨ãƒ»ç·¨é›†å¯èƒ½ ã§ã™ã€‚
å•†ç”¨åˆ©ç”¨ãƒ»è©æ¬ºãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¸ã®è»¢ç”¨ã¯ç¦æ­¢ã§ã™ã€‚

å‡ºå…¸ï¼š
â€œAI-Agent User Safety Advisory (2025)â€
ï¼ˆHanamaruki / SOVOS Repositoryï¼‰

---

English

This advisory may be freely reused, quoted, or modified
for the purpose of protecting users from AI agent risks.

Commercial exploitation or use in scam templates is strictly prohibited.

---

ğŸŸ¦ ã€æœ¬ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒªã®æ„å›³ã«ã¤ã„ã¦ï½œClarification of Intentã€‘
æ—¥æœ¬èª

æœ¬ãƒªãƒã‚¸ãƒˆãƒªã§å…¬é–‹ã—ã¦ã„ã‚‹æƒ…å ±ãŠã‚ˆã³è­¦å‘Šã¯ã€
AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’æ´»ç”¨ã™ã‚‹å…¨ä¸–ç•Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ä¼æ¥­ãƒ»æ•™è‚²è€…ãƒ»ç ”ç©¶è€…ã‚’ä¿è­·ã™ã‚‹ãŸã‚ ã«ä½œæˆã•ã‚ŒãŸã‚‚ã®ã§ã™ã€‚

ã“ã“ã§ç¤ºã•ã‚Œã‚‹å†…å®¹ã¯ã€ã„ã‹ãªã‚‹ä¼æ¥­ã€å›£ä½“ã€é–‹ç™ºè€…ã€ã¾ãŸã¯å€‹äººã‚’
éé›£ãƒ»æ”»æ’ƒãƒ»æ‰¹åˆ¤ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ãŸã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

æ€¥é€Ÿã«æ™®åŠã—ã¤ã¤ã‚ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ã«å¯¾ã—ã€
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ä¼æ¥­ãŒ äºˆæœŸã›ã¬é«˜é¡è«‹æ±‚ãƒ»è‡ªå¾‹è¡Œå‹•ãƒ»åˆ¶å¾¡ä¸èƒ½ãªæŒ™å‹•ã«ã‚ˆã‚‹æå®³ ã‚’é¿ã‘ã‚‹ãŸã‚ã®
â€œå…¬å…±çš„ãªå®‰å…¨ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒªï¼ˆPublic Safety Advisoryï¼‰â€ã§ã™ã€‚

AIæŠ€è¡“ã¯äººé¡ã«å¤§ããªåˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ã‚’æŒã¤ä¸€æ–¹ã€
é©åˆ‡ãªç†è§£ãƒ»èª¬æ˜ãƒ»å®‰å…¨è¨­è¨ˆãŒãªã‘ã‚Œã°äº‹æ•…ãŒç™ºç”Ÿã™ã‚‹ ã¨ã„ã†äº‹å®Ÿã‚’å…±æœ‰ã—ã€
ã™ã¹ã¦ã®åˆ©ç”¨è€…ãŒè‡ªã‚‰ã®è²¬ä»»ç¯„å›²ã‚’æŠŠæ¡ã—ãŸã†ãˆã§
ã‚ˆã‚Šå®‰å…¨ã«æŠ€è¡“ã‚’æ´»ç”¨ã§ãã‚‹æœªæ¥ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚

---

English

The information and warnings provided in this repository are created to protect global users, companies, educators, and researchers who use autonomous AI agents across various platforms.

This advisory does NOT aim to criticize, attack, or defame any company, developer, organization, or individual.

As autonomous agent technologies rapidly expand,
this document serves as a public safety advisory,
intended to help users and companies avoid unexpected high-cost billing, uncontrolled agent behavior, and unintended autonomous actions.

While AI technology has the potential to benefit humanity,
it can also lead to accidents without proper understanding, transparency, and safety mechanisms.

Our goal is to ensure that all users clearly understand the risks,
take appropriate precautions,
and can use these technologies more safely and responsibly.

---

ğŸ“Œ ã€è³‡æ–™ã«ã¤ã„ã¦ï½œAbout the Included Documentsã€‘

æ—¥æœ¬èªï¼ˆJPï¼‰
æœ¬ãƒªãƒã‚¸ãƒˆãƒªã«å«ã¾ã‚Œã‚‹è³‡æ–™ã¯ã€
AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ã®æ½œåœ¨çš„ãƒªã‚¹ã‚¯ã‚’ç†è§£ã™ã‚‹ãŸã‚ã®
æ•™è‚²ç›®çš„ã®å‚è€ƒæ–‡æ›¸ ã§ã™ã€‚

å®Ÿé¨“ãƒ­ã‚°ãŠã‚ˆã³ãƒ¢ãƒ‡ãƒ«ææ¡ˆã¯ã€
ç‰¹å®šã®ä¼æ¥­ã‚„è£½å“ã‚’æ‰¹åˆ¤ã™ã‚‹ã‚‚ã®ã§ã¯ãªãã€
å°†æ¥ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ä¼æ¥­ã‚’å®ˆã‚‹ãŸã‚ã®â€œå…¬å…±å®‰å…¨ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒªâ€ã®è£œè¶³è³‡æ–™ ã¨ã—ã¦å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚

---

Englishï¼ˆENï¼‰
The documents included in this repository are
educational reference materials
intended to help users and organizations understand potential risks associated with autonomous AI agents.

Both the experimental log and the proposed power-based billing model
are provided as supplementary public safety resources,
not as criticism toward any company or product.

---

Source:
â€œAI-Agent User Safety Advisory (2025)â€
(Hanamaruki / SOVOS Repository)
